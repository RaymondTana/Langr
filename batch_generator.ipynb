{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582952ee",
   "metadata": {},
   "source": [
    "## Batch Game Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f9210",
   "metadata": {},
   "source": [
    "Other possible clues:\n",
    "  - Other linguistic info about the language\n",
    "  - Place of origin: \n",
    "  - Specific to the audio sample: \n",
    "    - Wompy audio version\n",
    "  - Look into semantic scholar, only import if these fields are not blank or null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c1253",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b877e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF DAYS TO GENERATE USING THIS BATCH PROCESS\n",
    "number_to_generate = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb7d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langcodes import Language\n",
    "from datasets import load_dataset, Audio as HF_Audio\n",
    "import librosa, scipy.signal as sig\n",
    "from datetime import datetime\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import shutil, soundfile as sf\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e87007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "LANGUAGE_DATA_PATH = 'languages.csv'\n",
    "GAME_DATA_PATH = 'game_data.csv'\n",
    "CSV_PATH = Path(GAME_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bd3eb",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6569b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to sample from the languages list\n",
    "def sample_with_repeat_rounds(arr, N):\n",
    "    if not arr:\n",
    "        return []\n",
    "    result = []\n",
    "    while len(result) < N:\n",
    "        remaining = N - len(result)\n",
    "        draw_count = min(remaining, len(arr))\n",
    "        new_samples = random.sample(arr, draw_count)\n",
    "        result.extend(new_samples)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Count number of words in a string\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Request a sample from Mozilla's Common Voice\n",
    "def sample_common_voice(cv_code: str):\n",
    "    version = 15\n",
    "    try:\n",
    "        ds_stream = load_dataset(\n",
    "            f'mozilla-foundation/common_voice_{version}_0',\n",
    "            name = cv_code, \n",
    "            split = 'train',\n",
    "            streaming = True\n",
    "            # token = os.environ[\"HF_TOKEN\"]\n",
    "        )\n",
    "        ds_stream.cast_column('audio', HF_Audio(decode = True))\n",
    "        seed = random.randint(0, 2**32 - 1)\n",
    "        ds_shuffled = ds_stream.shuffle(buffer_size=2048, seed=seed)\n",
    "\n",
    "        samples = list(ds_shuffled.take(5))\n",
    "        for sample in samples:\n",
    "            if sample['audio']['array'].shape[0] >= 200000:\n",
    "                print(f'Loaded a sample from Common Voice dataset for {cv_code} that was long enough >:)')\n",
    "                return [sample]\n",
    "        print(f'Loaded a sample from Common Voice dataset for {cv_code} but it was too short :3')\n",
    "        return [samples[0]]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Failed to sample from the Common Voice dataset:\\n{e}')\n",
    "        return []\n",
    "\n",
    "# Exploit Google Translate to translate this sentence (webscraping!)\n",
    "def translate(language, text):\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    try:\n",
    "        # Navigate to Google Translate\n",
    "        driver.get(\"https://translate.google.com\")\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        actions = ActionChains(driver)\n",
    "        \n",
    "        # Wait for page to load\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Enter text (cursor should be ready in text area)\n",
    "        actions.send_keys(text).perform()\n",
    "        \n",
    "        # Find and click the target language button\n",
    "        target_lang_button = wait.until(EC.element_to_be_clickable((\n",
    "            By.CSS_SELECTOR, \n",
    "            \"button[aria-label*='target language'], .VfPpkd-Bz112c-RLmnJb\"\n",
    "        )))\n",
    "        target_lang_button.click()\n",
    "        \n",
    "        # Wait briefly for dropdown, then type language and press Enter\n",
    "        time.sleep(0.5)\n",
    "        actions.send_keys(language).perform()\n",
    "        time.sleep(0.5)\n",
    "        actions.send_keys(Keys.RETURN).perform()\n",
    "        \n",
    "        # Wait for translation and extract\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Extract translation\n",
    "        translation_selectors = [\n",
    "            \"span[jsname='W297wb']\",\n",
    "            \"span[lang]:not([lang='auto']):not([lang=''])\",\n",
    "            \".ryNqvb span\",\n",
    "            \".J0lOec span\"\n",
    "        ]\n",
    "        \n",
    "        for selector in translation_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for element in elements:\n",
    "                    translated_text = element.text.strip()\n",
    "                    if translated_text and translated_text != text:\n",
    "                        print(f\"Translation found: {translated_text}\")\n",
    "                        return translated_text\n",
    "            except:\n",
    "                continue\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def find_espeak():\n",
    "    \"\"\"Return path to espeak-ng or espeak binary, raise if missing.\"\"\"\n",
    "    exe = shutil.which(\"espeak-ng\") or shutil.which(\"espeak\")\n",
    "    if exe is None:\n",
    "        raise FileNotFoundError(\"No espeak-ng/espeak binary on PATH\")\n",
    "    return exe\n",
    "\n",
    "def phonemize(text: str, lang: str = \"en\", ipa: bool = False,\n",
    "              ipa_level: int = 1, keep_stress: bool = True) -> str:\n",
    "    \"\"\"Phonemize text using eSpeak (NG)\"\"\"\n",
    "    try: \n",
    "        exe = find_espeak()\n",
    "\n",
    "        # Build the command line\n",
    "        args = [exe, \"-q\", f\"-v{lang}\"]\n",
    "        if ipa:\n",
    "            args.append(f\"--ipa={ipa_level}\")\n",
    "        else:\n",
    "            args.append(\"-x\")\n",
    "            if not keep_stress:\n",
    "                args.append(\"--sep=-\") # do this to strip stress marks later\n",
    "        args.append(text)\n",
    "\n",
    "        # Run the command\n",
    "        proc = subprocess.run(args, text = True, capture_output = True, check = True)\n",
    "        out = proc.stdout.strip()\n",
    "\n",
    "        if not keep_stress:\n",
    "            # eSpeak stress marks are the `'` characters; remove them\n",
    "            out = out.replace(\"ˈ\", \"\")\n",
    "\n",
    "        # Sometimes line breaks appear in the output; remove them\n",
    "        out = out.replace(\"\\n\", \" \").replace(\"_\", \"\").replace(\"\\r\", \" \").strip()\n",
    "\n",
    "        return out\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting IPA representation, enter manually: {str(e)}\")\n",
    "        return \"???\"\n",
    "    \n",
    "def get_row(chosen_language, day, languages_df):\n",
    "    # Get language data from languages dataframe\n",
    "    languages_row = languages_df[languages_df['espeak_code'] == chosen_language].iloc[0]\n",
    "    LANGUAGE = { \n",
    "        'ESPEAK_CODE': chosen_language,\n",
    "        'ENGLISH_NAME' : languages_row['english_name'], \n",
    "        'ISO' : languages_row['iso3'],  \n",
    "        'CV' : languages_row['cv_code'], \n",
    "        'ESPEAK' : languages_row['espeak_code'], \n",
    "        'LINEAGE' : eval(languages_row['lineage']), \n",
    "        'FAMILY_0' : languages_row['family_0'], \n",
    "        'FAMILY_1' : languages_row['family_1'], \n",
    "        'FAMILY_2' : languages_row['family_2']\n",
    "    }\n",
    "\n",
    "    print(f\"Generating an example for {LANGUAGE['ENGLISH_NAME']} ({LANGUAGE['ESPEAK_CODE']})\")\n",
    "\n",
    "    # Get a sample from that language\n",
    "    LANGUAGE['SAMPLE'] = sample_common_voice(LANGUAGE['CV'])\n",
    "    LANGUAGE['SAMPLE'][0]['sentence'] = LANGUAGE['SAMPLE'][0]['sentence'].replace('\\n', ' ')\n",
    "\n",
    "    # Try to translate it\n",
    "    try:\n",
    "        LANGUAGE['SAMPLE'][0]['translation'] = translate(LANGUAGE['ENGLISH_NAME'], LANGUAGE['SAMPLE'][0]['sentence'])\n",
    "    except Exception as e:\n",
    "        print(f'Failed to add translation, enter it manually:\\n{e}')\n",
    "        LANGUAGE['SAMPLE'][0]['translation'] = '???????'\n",
    "\n",
    "    # Extract audio data of sample\n",
    "    wave = LANGUAGE['SAMPLE'][0]['audio']['array']\n",
    "    rate = LANGUAGE['SAMPLE'][0]['audio']['sampling_rate']\n",
    "\n",
    "    # Convert to phonetics\n",
    "    LANGUAGE['SAMPLE'][0]['IPA'] = phonemize(text = LANGUAGE['SAMPLE'][0]['sentence'], lang = LANGUAGE['ESPEAK'], ipa = True, ipa_level = 1, keep_stress = False)\n",
    "\n",
    "    # Generate and store corresponding audio file\n",
    "    AUDIO_DIR = Path('assets/audio')\n",
    "    AUDIO_DIR.mkdir(exist_ok = True)\n",
    "    fname_base = f\"{day:%Y-%m-%d}\"\n",
    "    file_path = AUDIO_DIR / f\"{fname_base}.mp3\"\n",
    "    # muffled_file_path = AUDIO_DIR / f\"{fname_base}_muffled.mp3\"\n",
    "    # muffled_wave = sig.sosfiltfilt(sig.butter(1, 700, \"low\", fs = rate, output = \"sos\"),\n",
    "    #                          librosa.effects.pitch_shift(wave.astype(np.float32), sr = rate, n_steps = -2))\n",
    "    sf.write(file_path, wave, rate, format='MP3')\n",
    "    # sf.write(muffled_file_path, muffled_wave, rate, format='WAV')\n",
    "\n",
    "    # build a new row based on the generated LANGUAGE dict from above\n",
    "    new_row = { 'date': day,\n",
    "                'language': LANGUAGE['ENGLISH_NAME'],\n",
    "                'iso': LANGUAGE['ISO'],\n",
    "                'cv_code': LANGUAGE['CV'],\n",
    "                'espeak_code': LANGUAGE['ESPEAK'],\n",
    "                'lineage': LANGUAGE['LINEAGE'],\n",
    "                'family_0': LANGUAGE['FAMILY_0'],\n",
    "                'family_1': LANGUAGE['FAMILY_1'],\n",
    "                'family_2': LANGUAGE['FAMILY_2'],\n",
    "                'sentence': LANGUAGE['SAMPLE'][0]['sentence'],\n",
    "                'translation': LANGUAGE['SAMPLE'][0]['translation'],\n",
    "                'wave': file_path.name,\n",
    "                # 'muffled_wave': muffled_file_path.name,\n",
    "                'sampling_rate': LANGUAGE['SAMPLE'][0]['audio']['sampling_rate'],\n",
    "                'IPA': LANGUAGE['SAMPLE'][0]['IPA']\n",
    "    }\n",
    "\n",
    "    return new_row\n",
    "    \n",
    "def fill_day(chosen_language, day, languages_df, game_df, CSV_PATH):\n",
    "    new_row = get_row(chosen_language, day, languages_df)\n",
    "    # ensure any new columns are present in the dataframe\n",
    "    missing_cols = set(new_row) - set(game_df.columns)\n",
    "    for c in missing_cols:\n",
    "        game_df[c] = pd.NA # create blank column for any new field\n",
    "\n",
    "    # append and reset the index\n",
    "    game_df = pd.concat([game_df, pd.DataFrame([new_row])], ignore_index = True)\n",
    "\n",
    "    # store into the game_df\n",
    "    game_df.to_csv(CSV_PATH, index = False)\n",
    "\n",
    "    print(f\"Filled {day:%Y-%m-%d} with {new_row['language']}\\n\")\n",
    "    \n",
    "\n",
    "def replace_day(chosen_language, day, languages_df, game_df, CSV_PATH):\n",
    "    # Find index for matching date\n",
    "    datetime_object = datetime.strptime(day, \"%Y-%m-%d\").date()\n",
    "    mask = game_df['date'] == datetime_object\n",
    "    hits = mask.sum()\n",
    "    if hits == 0:\n",
    "        raise KeyError(f\"No row found with date {day}\")\n",
    "    if hits > 1:\n",
    "        raise KeyError(f\"Expected one row with date {day}, found {hits}\")\n",
    "    \n",
    "    new_row = get_row(chosen_language, datetime_object, languages_df)\n",
    "    pd_new_row = (pd.Series(new_row).reindex(game_df.columns, fill_value=pd.NA))\n",
    "    \n",
    "    idx = game_df.index[mask][0]\n",
    "    game_df.loc[idx] = pd_new_row\n",
    "\n",
    "    # store into the game_df\n",
    "    game_df.to_csv(CSV_PATH, index = False)\n",
    "\n",
    "    print(f\"Replaced {day} with {new_row['language']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074ab8b",
   "metadata": {},
   "source": [
    "## Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e4e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating an example for Danish (da)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 3381it [00:00, 22613.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for da that was long enough >:)\n",
      "Translation found: Roses shouldn't be able to tolerate the smoke, they will change color, turn green.\n",
      "Filled 2025-10-18 with Danish\n",
      "\n",
      "Generating an example for Portuguese (pt-pt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 21202it [00:00, 40275.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for pt but it was too short :3\n",
      "Filled 2025-10-19 with Portuguese\n",
      "\n",
      "Generating an example for Finnish (fi)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 2148it [00:00, 16442.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for fi that was long enough >:)\n",
      "Translation found: Houses had been built on top of each other, as needed, to accommodate all the people living in the city.\n",
      "Filled 2025-10-20 with Finnish\n",
      "\n",
      "Generating an example for Romanian (ro)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 5172it [00:00, 29159.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ro that was long enough >:)\n",
      "Filled 2025-10-21 with Romanian\n",
      "\n",
      "Generating an example for Macedonian (mk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 67it [00:00, 1058.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for mk that was long enough >:)\n",
      "Translation found: Relativistic corrections are also needed for quantum mechanics.\n",
      "Filled 2025-10-22 with Macedonian\n",
      "\n",
      "Generating an example for Catalan (ca)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 1142607it [00:37, 30120.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ca that was long enough >:)\n",
      "Translation found: White chose the color pink, and worked with musician Greg Weeks.\n",
      "Filled 2025-10-23 with Catalan\n",
      "\n",
      "Generating an example for Malayalam (ml)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 1249it [00:00, 12222.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ml that was long enough >:)\n",
      "Translation found: This is a completely impractical and very expensive option for broiler farms with thousands of chickens.\n",
      "Filled 2025-10-24 with Malayalam\n",
      "\n",
      "Generating an example for French (fr-fr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 527554it [00:18, 29204.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for fr that was long enough >:)\n",
      "Translation found: He is the second referee to officiate a final after Albert Alsteen.\n",
      "Filled 2025-10-25 with French\n",
      "\n",
      "Generating an example for Indonesian (id)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 4968it [00:00, 27965.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for id that was long enough >:)\n",
      "Translation found: The event is very far from where I work and live, but I appreciate your concern.\n",
      "Filled 2025-10-26 with Indonesian\n",
      "\n",
      "Generating an example for French (fr-be)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 527554it [00:15, 34339.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for fr that was long enough >:)\n",
      "Translation found: Ten shillings became a dollar and a shilling became worth ten cents.\n",
      "Filled 2025-10-27 with French\n",
      "\n",
      "Generating an example for Swedish (sv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 7584it [00:00, 23712.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sv-SE but it was too short :3\n",
      "Translation found: That's so awesome!\n",
      "Filled 2025-10-28 with Swedish\n",
      "\n",
      "Generating an example for Mandarin (zh)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 7048it [00:00, 27210.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for zh-TW that was long enough >:)\n",
      "Translation found: Important but unpopular issues\n",
      "Filled 2025-10-29 with Mandarin\n",
      "\n",
      "Generating an example for Spanish (es-la)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 311392it [00:11, 27355.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for es that was long enough >:)\n",
      "Translation found: The plumage of its upper parts is olive green.\n",
      "Filled 2025-10-30 with Spanish\n",
      "\n",
      "Generating an example for Hungarian (hu)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 34498it [00:01, 33380.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for hu that was long enough >:)\n",
      "Translation found: Until the Treaty of Trianon, Spiš County belonged to the Késmárki district.\n",
      "Filled 2025-10-31 with Hungarian\n",
      "\n",
      "Generating an example for Icelandic (is)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 8it [00:00, 125.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for is that was long enough >:)\n",
      "Translation found: Borgarholtsskóli is a secondary school on Mosavegur Road in Grafarvogur, Reykjavík.\n",
      "Filled 2025-11-01 with Icelandic\n",
      "\n",
      "Generating an example for Albanian (sq)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 494it [00:00, 3792.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sq that was long enough >:)\n",
      "Translation found: No, no, we didn't vote.\n",
      "Filled 2025-11-02 with Albanian\n",
      "\n",
      "Generating an example for Swahili (sw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 44075it [00:01, 38401.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sw that was long enough >:)\n",
      "Translation found: writing the true history of African struggles, your words will always remain as an inspiration\n",
      "Filled 2025-11-03 with Swahili\n",
      "\n",
      "Generating an example for Estonian (et)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 3148it [00:00, 20432.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for et that was long enough >:)\n",
      "Translation found: More protein - this is a good long-term strategy against belly fat.\n",
      "Filled 2025-11-04 with Estonian\n",
      "\n",
      "Generating an example for Bulgarian (bg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 3413it [00:00, 15127.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for bg that was long enough >:)\n",
      "Translation found: However, he rarely hit: in the Kalofer school I found more humane relations.\n",
      "Filled 2025-11-05 with Bulgarian\n",
      "\n",
      "Generating an example for Lithuanian (lt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 6715it [00:00, 17307.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for lt that was long enough >:)\n",
      "Translation found: Events honoring the winners of the Stanislovas Rapolionis Prize are held at the gymnasium.\n",
      "Filled 2025-11-06 with Lithuanian\n",
      "\n",
      "Generating an example for Russian (ru)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 26328it [00:01, 23406.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ru that was long enough >:)\n",
      "Translation found: Can you hold back a tornado so that it doesn’t boil like a whirlwind?!\n",
      "Filled 2025-11-07 with Russian\n",
      "\n",
      "Generating an example for Italian (it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 166503it [00:04, 33836.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for it that was long enough >:)\n",
      "Translation found: In Cantù, a street in the town centre was named after him.\n",
      "Filled 2025-11-08 with Italian\n",
      "\n",
      "Generating an example for Afrikaans (af)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 15it [00:00, 227.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for af that was long enough >:)\n",
      "Translation found: Then they walked back to their hiding place.\n",
      "Filled 2025-11-09 with Afrikaans\n",
      "\n",
      "Generating an example for Spanish (es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 311392it [00:09, 31321.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for es that was long enough >:)\n",
      "Translation found: Robinson's work explores alternatives to modern capitalism.\n",
      "Filled 2025-11-10 with Spanish\n",
      "\n",
      "Generating an example for Persian (fa)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 28756it [00:00, 30657.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for fa that was long enough >:)\n",
      "Translation found: Some of that ambassador's statements were confusing.\n",
      "Filled 2025-11-11 with Persian\n",
      "\n",
      "Generating an example for Esperanto (eo)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 144070it [00:05, 27125.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for eo that was long enough >:)\n",
      "Translation found: According to him, it would be necessary for Esperanto organizations to take steps to preserve them, while that is possible.\n",
      "Filled 2025-11-12 with Esperanto\n",
      "\n",
      "Generating an example for Cantonese (zh-yue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 3074it [00:00, 17733.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for yue that was long enough >:)\n",
      "Translation found: I need to eat, I'm hungry!\n",
      "Filled 2025-11-13 with Cantonese\n",
      "\n",
      "Generating an example for Serbian (sr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 1521it [00:00, 14478.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sr but it was too short :3\n",
      "Translation found: Since the proposal was accepted\n",
      "Filled 2025-11-14 with Serbian\n",
      "\n",
      "Generating an example for Dutch (nl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 34088it [00:01, 30572.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for nl that was long enough >:)\n",
      "Translation found: As an observer, you know that the problem remains unsolved, even though we tried.\n",
      "Filled 2025-11-15 with Dutch\n",
      "\n",
      "Generating an example for Tamil (ta)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 44044it [00:02, 18647.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ta that was long enough >:)\n",
      "Translation found: To speak to the people within the Nishapur government boundaries.\n",
      "Filled 2025-11-16 with Tamil\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All available languages, removing english\n",
    "languages_df = pd.read_csv(LANGUAGE_DATA_PATH)\n",
    "all_languages = languages_df['espeak_code'].unique()\n",
    "for code in ['en', 'en-gb', 'en-sc', 'en-uk-north', 'en-uk-wmids', 'en-us', 'en-wi']:\n",
    "    all_languages = np.delete(all_languages, np.where(all_languages == code))\n",
    "all_languages\n",
    "\n",
    "# Select number_to_generate many languages, with some non-repetition baked into this choice\n",
    "sample = sample_with_repeat_rounds(list(all_languages), number_to_generate)\n",
    "\n",
    "START_DAY = date(2025, 6, 13) # first day in the daily games series\n",
    "\n",
    "# Generate examples\n",
    "for chosen_language in sample:\n",
    "\n",
    "    # Load the dataframe\n",
    "    if CSV_PATH.exists():\n",
    "        game_df = pd.read_csv(CSV_PATH, parse_dates = ['date'])\n",
    "        # mutate the column to a Python date, not Timestamp\n",
    "        game_df['date'] = game_df['date'].dt.date\n",
    "    else:\n",
    "        game_df = pd.DataFrame(columns=['date'])\n",
    "\n",
    "    # Decide date to which this example corresponds\n",
    "    next_day = (max(game_df['date']) + timedelta(days = 1)) if not game_df.empty else START_DAY\n",
    "\n",
    "    # Fill in the next day with an example of the chosen language\n",
    "    fill_day(chosen_language, next_day, languages_df, game_df, CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ea99e",
   "metadata": {},
   "source": [
    "## Replacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615f81e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating an example for Swahili (sw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 44075it [00:02, 16429.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sw that was long enough >:)\n",
      "Clicked target language dropdown\n",
      "Translation found: denied entry to Chinese people, the law aimed to reduce\n",
      "Replaced 2025-07-01 with Swahili)\n"
     ]
    }
   ],
   "source": [
    "# Manually replacing\n",
    "date_string = \"2025-07-01\"\n",
    "\n",
    "# Load the dataframe\n",
    "if CSV_PATH.exists():\n",
    "    game_df = pd.read_csv(CSV_PATH, parse_dates = ['date'])\n",
    "    game_df['date'] = game_df['date'].dt.date\n",
    "else:\n",
    "    game_df = pd.DataFrame(columns=['date'])\n",
    "\n",
    "# Replace the example for this date with language of choice\n",
    "replace_day('sw', date_string, pd.read_csv(LANGUAGE_DATA_PATH), game_df, Path(GAME_DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9a419",
   "metadata": {},
   "source": [
    "## View Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c78d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>iso</th>\n",
       "      <th>family_2</th>\n",
       "      <th>translation</th>\n",
       "      <th>sentence</th>\n",
       "      <th>family_0</th>\n",
       "      <th>lineage</th>\n",
       "      <th>espeak_code</th>\n",
       "      <th>family_1</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>IPA</th>\n",
       "      <th>wave</th>\n",
       "      <th>language</th>\n",
       "      <th>cv_code</th>\n",
       "      <th>muffled_wave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>hin</td>\n",
       "      <td>Shaurasenic</td>\n",
       "      <td>These apps will make your train journey easier</td>\n",
       "      <td>ये एप्स आपके ट्रेन के सफर को बनाएंगे और आसान</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>hi</td>\n",
       "      <td>Indo-Iranian</td>\n",
       "      <td>48000</td>\n",
       "      <td>jeː ˈeːps ˌaːpkˌeː ʈɾˈeːn keː sˈʌpʰəɾ koː bˌən...</td>\n",
       "      <td>2025-07-06.mp3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>hi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>vie</td>\n",
       "      <td>Viet-Muong</td>\n",
       "      <td>I took the pack of cigarettes out to the porch...</td>\n",
       "      <td>Tôi cầm bao thuốc ra bên ngoài hiên hóng gió</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...</td>\n",
       "      <td>vi</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>48000</td>\n",
       "      <td>t̪ˈo͡ɪ1 ɡˈə2m bˈaː͡ʊ1 tˈu͡əɜk͡h zˈaː1 bˈe1n ŋˈ...</td>\n",
       "      <td>2025-07-07.mp3</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>vi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>nep</td>\n",
       "      <td>Eastern Pahari</td>\n",
       "      <td>If anyone has a program that can be held on th...</td>\n",
       "      <td>यदि कसैको क्याम्पसमा कार्यक्रम गर्न मिल्ने छ भ...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>ne</td>\n",
       "      <td>Indo-Iranian</td>\n",
       "      <td>48000</td>\n",
       "      <td>jˈʌdɪ kəsˈɛːkoː kːjˈaːmpəsˌəmaː kˈaːɾrjəkɾˌəmə...</td>\n",
       "      <td>2025-07-08.mp3</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>ne-NP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>vie</td>\n",
       "      <td>Viet–Mường</td>\n",
       "      <td>Looking at the clock, it was already ten o'clo...</td>\n",
       "      <td>Nhìn đồng hồ lúc này cũng đã là mười giờ tối</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...</td>\n",
       "      <td>vi-hue</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>48000</td>\n",
       "      <td>ɲˈi2ŋ ɗˈo2 hˈo2 lˌuɜk͡h nˈa͡ɪ2 ɡˈu5ŋ ɗˌaː5 lˌa...</td>\n",
       "      <td>2025-07-09.mp3</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>vi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>ell</td>\n",
       "      <td>Modern Koineic</td>\n",
       "      <td>His knees buckled for a moment and he leaned a...</td>\n",
       "      <td>Τα γόνατά του κόπηκαν προς στιγμή και ακούμπησ...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>el</td>\n",
       "      <td>Graeco-Phrygian</td>\n",
       "      <td>48000</td>\n",
       "      <td>ta ɣˈonatˈa tu kˈopikˌam brˈos stiɣmˈi ke akˈu...</td>\n",
       "      <td>2025-07-10.mp3</td>\n",
       "      <td>Greek</td>\n",
       "      <td>el</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>cym</td>\n",
       "      <td>Brythonic</td>\n",
       "      <td>Porridge is oatmeal boiled in water or milk.</td>\n",
       "      <td>Blawd ceirch wedi'i ferwi mewn dŵr neu laeth y...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>cy</td>\n",
       "      <td>Celtic</td>\n",
       "      <td>48000</td>\n",
       "      <td>blˈa͡ʊd kˈə͡ɪrx wɛdˈiːɨ vˈɛrwɨ me͡ʊn dˈuːr nˈə...</td>\n",
       "      <td>2025-07-11.mp3</td>\n",
       "      <td>Welsh</td>\n",
       "      <td>cy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-07-12</td>\n",
       "      <td>mkd</td>\n",
       "      <td>South Slavic</td>\n",
       "      <td>The houses are incredibly realistic, with mode...</td>\n",
       "      <td>Куќичките се неверојатно реални, со модерни де...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>mk</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>48000</td>\n",
       "      <td>kʊk^ˈit͡ɕkɪtˌe se nˌeverˈojætnˌo rˈeælnˌɪ\\n s ...</td>\n",
       "      <td>2025-07-12.mp3</td>\n",
       "      <td>Macedonian</td>\n",
       "      <td>mk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-07-13</td>\n",
       "      <td>lit</td>\n",
       "      <td>Eastern Baltic</td>\n",
       "      <td>Its area is about half the area of Abruzzo.</td>\n",
       "      <td>Jos plotas sudaro apie pusę Abrucų ploto.</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>lt</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>48000</td>\n",
       "      <td>jˈoːs pl̩ˈoːtas sudˈaroː ˈapʲi͡e pˈuʂe͡ɑ abrˈu...</td>\n",
       "      <td>2025-07-13.mp3</td>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>lt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>fin</td>\n",
       "      <td>Coastal Finnic</td>\n",
       "      <td>Or has some other species, perhaps a bacterium...</td>\n",
       "      <td>Vai onko jokin muu laji, bakteeri kenties, tuh...</td>\n",
       "      <td>Uralic</td>\n",
       "      <td>['Uralic', 'Finnic', 'Coastal Finnic', 'Neva',...</td>\n",
       "      <td>fi</td>\n",
       "      <td>Finnic</td>\n",
       "      <td>48000</td>\n",
       "      <td>va͡i ˈoŋko jˈokɪn mˈuː lˈajɪ\\n bˈakteːrɪ kˈent...</td>\n",
       "      <td>2025-07-14.mp3</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>fi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-07-15</td>\n",
       "      <td>afr</td>\n",
       "      <td>Macro-Dutch</td>\n",
       "      <td>Your school choir performed the choral works b...</td>\n",
       "      <td>Jou skoolkoor het die koorwerke hieronder gedu...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>af</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>48000</td>\n",
       "      <td>jə͡ʊ skˈʊ͡əlkʊ͡ər hɛ di kˈʊ͡ərværkə hˈiːrɔnər ...</td>\n",
       "      <td>2025-07-15.mp3</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>af</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  iso        family_2  \\\n",
       "23  2025-07-06  hin     Shaurasenic   \n",
       "24  2025-07-07  vie      Viet-Muong   \n",
       "25  2025-07-08  nep  Eastern Pahari   \n",
       "26  2025-07-09  vie      Viet–Mường   \n",
       "27  2025-07-10  ell  Modern Koineic   \n",
       "28  2025-07-11  cym       Brythonic   \n",
       "29  2025-07-12  mkd    South Slavic   \n",
       "30  2025-07-13  lit  Eastern Baltic   \n",
       "31  2025-07-14  fin  Coastal Finnic   \n",
       "32  2025-07-15  afr     Macro-Dutch   \n",
       "\n",
       "                                          translation  \\\n",
       "23     These apps will make your train journey easier   \n",
       "24  I took the pack of cigarettes out to the porch...   \n",
       "25  If anyone has a program that can be held on th...   \n",
       "26  Looking at the clock, it was already ten o'clo...   \n",
       "27  His knees buckled for a moment and he leaned a...   \n",
       "28       Porridge is oatmeal boiled in water or milk.   \n",
       "29  The houses are incredibly realistic, with mode...   \n",
       "30        Its area is about half the area of Abruzzo.   \n",
       "31  Or has some other species, perhaps a bacterium...   \n",
       "32  Your school choir performed the choral works b...   \n",
       "\n",
       "                                             sentence       family_0  \\\n",
       "23       ये एप्स आपके ट्रेन के सफर को बनाएंगे और आसान  Indo-European   \n",
       "24       Tôi cầm bao thuốc ra bên ngoài hiên hóng gió  Austroasiatic   \n",
       "25  यदि कसैको क्याम्पसमा कार्यक्रम गर्न मिल्ने छ भ...  Indo-European   \n",
       "26       Nhìn đồng hồ lúc này cũng đã là mười giờ tối  Austroasiatic   \n",
       "27  Τα γόνατά του κόπηκαν προς στιγμή και ακούμπησ...  Indo-European   \n",
       "28  Blawd ceirch wedi'i ferwi mewn dŵr neu laeth y...  Indo-European   \n",
       "29  Куќичките се неверојатно реални, со модерни де...  Indo-European   \n",
       "30          Jos plotas sudaro apie pusę Abrucų ploto.  Indo-European   \n",
       "31  Vai onko jokin muu laji, bakteeri kenties, tuh...         Uralic   \n",
       "32  Jou skoolkoor het die koorwerke hieronder gedu...  Indo-European   \n",
       "\n",
       "                                              lineage espeak_code  \\\n",
       "23  ['Indo-European', 'Classical Indo-European', '...          hi   \n",
       "24  ['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...          vi   \n",
       "25  ['Indo-European', 'Classical Indo-European', '...          ne   \n",
       "26  ['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...      vi-hue   \n",
       "27  ['Indo-European', 'Classical Indo-European', '...          el   \n",
       "28  ['Indo-European', 'Classical Indo-European', '...          cy   \n",
       "29  ['Indo-European', 'Classical Indo-European', '...          mk   \n",
       "30  ['Indo-European', 'Classical Indo-European', '...          lt   \n",
       "31  ['Uralic', 'Finnic', 'Coastal Finnic', 'Neva',...          fi   \n",
       "32  ['Indo-European', 'Classical Indo-European', '...          af   \n",
       "\n",
       "           family_1  sampling_rate  \\\n",
       "23     Indo-Iranian          48000   \n",
       "24           Vietic          48000   \n",
       "25     Indo-Iranian          48000   \n",
       "26           Vietic          48000   \n",
       "27  Graeco-Phrygian          48000   \n",
       "28           Celtic          48000   \n",
       "29     Balto-Slavic          48000   \n",
       "30     Balto-Slavic          48000   \n",
       "31           Finnic          48000   \n",
       "32         Germanic          48000   \n",
       "\n",
       "                                                  IPA            wave  \\\n",
       "23  jeː ˈeːps ˌaːpkˌeː ʈɾˈeːn keː sˈʌpʰəɾ koː bˌən...  2025-07-06.mp3   \n",
       "24  t̪ˈo͡ɪ1 ɡˈə2m bˈaː͡ʊ1 tˈu͡əɜk͡h zˈaː1 bˈe1n ŋˈ...  2025-07-07.mp3   \n",
       "25  jˈʌdɪ kəsˈɛːkoː kːjˈaːmpəsˌəmaː kˈaːɾrjəkɾˌəmə...  2025-07-08.mp3   \n",
       "26  ɲˈi2ŋ ɗˈo2 hˈo2 lˌuɜk͡h nˈa͡ɪ2 ɡˈu5ŋ ɗˌaː5 lˌa...  2025-07-09.mp3   \n",
       "27  ta ɣˈonatˈa tu kˈopikˌam brˈos stiɣmˈi ke akˈu...  2025-07-10.mp3   \n",
       "28  blˈa͡ʊd kˈə͡ɪrx wɛdˈiːɨ vˈɛrwɨ me͡ʊn dˈuːr nˈə...  2025-07-11.mp3   \n",
       "29  kʊk^ˈit͡ɕkɪtˌe se nˌeverˈojætnˌo rˈeælnˌɪ\\n s ...  2025-07-12.mp3   \n",
       "30  jˈoːs pl̩ˈoːtas sudˈaroː ˈapʲi͡e pˈuʂe͡ɑ abrˈu...  2025-07-13.mp3   \n",
       "31  va͡i ˈoŋko jˈokɪn mˈuː lˈajɪ\\n bˈakteːrɪ kˈent...  2025-07-14.mp3   \n",
       "32  jə͡ʊ skˈʊ͡əlkʊ͡ər hɛ di kˈʊ͡ərværkə hˈiːrɔnər ...  2025-07-15.mp3   \n",
       "\n",
       "      language cv_code  muffled_wave  \n",
       "23       Hindi      hi           NaN  \n",
       "24  Vietnamese      vi           NaN  \n",
       "25      Nepali   ne-NP           NaN  \n",
       "26  Vietnamese      vi           NaN  \n",
       "27       Greek      el           NaN  \n",
       "28       Welsh      cy           NaN  \n",
       "29  Macedonian      mk           NaN  \n",
       "30  Lithuanian      lt           NaN  \n",
       "31     Finnish      fi           NaN  \n",
       "32   Afrikaans      af           NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_df.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
