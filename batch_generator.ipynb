{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582952ee",
   "metadata": {},
   "source": [
    "## Batch Game Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f9210",
   "metadata": {},
   "source": [
    "Other possible clues:\n",
    "  - Other linguistic info about the language\n",
    "  - Place of origin: \n",
    "  - Specific to the audio sample: \n",
    "    - Wompy audio version\n",
    "  - Look into semantic scholar, only import if these fields are not blank or null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c1253",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b877e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF DAYS TO GENERATE USING THIS BATCH PROCESS\n",
    "number_to_generate = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb7d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langcodes import Language\n",
    "from datasets import load_dataset, Audio as HF_Audio\n",
    "import librosa, scipy.signal as sig\n",
    "from datetime import datetime\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import shutil, soundfile as sf\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e87007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "LANGUAGE_DATA_PATH = 'languages.csv'\n",
    "GAME_DATA_PATH = 'game_data.csv'\n",
    "CSV_PATH = Path(GAME_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bd3eb",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6569b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to sample from the languages list\n",
    "def sample_with_repeat_rounds(arr, N):\n",
    "    if not arr:\n",
    "        return []\n",
    "    result = []\n",
    "    while len(result) < N:\n",
    "        remaining = N - len(result)\n",
    "        draw_count = min(remaining, len(arr))\n",
    "        new_samples = random.sample(arr, draw_count)\n",
    "        result.extend(new_samples)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Count number of words in a string\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Request a sample from Mozilla's Common Voice\n",
    "def sample_common_voice(cv_code: str):\n",
    "    version = 15\n",
    "    try:\n",
    "        ds_stream = load_dataset(\n",
    "            f'mozilla-foundation/common_voice_{version}_0',\n",
    "            name = cv_code, \n",
    "            split = 'train',\n",
    "            streaming = True\n",
    "            # token = os.environ[\"HF_TOKEN\"]\n",
    "        )\n",
    "        ds_stream.cast_column('audio', HF_Audio(decode = True))\n",
    "        seed = random.randint(0, 2**32 - 1)\n",
    "        ds_shuffled = ds_stream.shuffle(buffer_size=2048, seed=seed)\n",
    "\n",
    "        samples = list(ds_shuffled.take(5))\n",
    "        for sample in samples:\n",
    "            if sample['audio']['array'].shape[0] >= 200000:\n",
    "                print(f'Loaded a sample from Common Voice dataset for {cv_code} that was long enough >:)')\n",
    "                return [sample]\n",
    "        print(f'Loaded a sample from Common Voice dataset for {cv_code} but it was too short :3')\n",
    "        return [samples[0]]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Failed to sample from the Common Voice dataset:\\n{e}')\n",
    "        return []\n",
    "\n",
    "# Exploit Google Translate to translate this sentence (webscraping!)\n",
    "def translate(language, text):\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    try:\n",
    "        # Navigate to Google Translate\n",
    "        driver.get(\"https://translate.google.com\")\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        actions = ActionChains(driver)\n",
    "        \n",
    "        # Wait for page to load\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Enter text (cursor should be ready in text area)\n",
    "        actions.send_keys(text).perform()\n",
    "        \n",
    "        # Find and click the target language button\n",
    "        target_lang_button = wait.until(EC.element_to_be_clickable((\n",
    "            By.CSS_SELECTOR, \n",
    "            \"button[aria-label*='target language'], .VfPpkd-Bz112c-RLmnJb\"\n",
    "        )))\n",
    "        target_lang_button.click()\n",
    "        \n",
    "        # Wait briefly for dropdown, then type language and press Enter\n",
    "        time.sleep(0.5)\n",
    "        actions.send_keys(language).perform()\n",
    "        time.sleep(0.5)\n",
    "        actions.send_keys(Keys.RETURN).perform()\n",
    "        \n",
    "        # Wait for translation and extract\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Extract translation\n",
    "        translation_selectors = [\n",
    "            \"span[jsname='W297wb']\",\n",
    "            \"span[lang]:not([lang='auto']):not([lang=''])\",\n",
    "            \".ryNqvb span\",\n",
    "            \".J0lOec span\"\n",
    "        ]\n",
    "        \n",
    "        for selector in translation_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for element in elements:\n",
    "                    translated_text = element.text.strip()\n",
    "                    if translated_text and translated_text != text:\n",
    "                        print(f\"Translation found: {translated_text}\")\n",
    "                        return translated_text\n",
    "            except:\n",
    "                continue\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def find_espeak():\n",
    "    \"\"\"Return path to espeak-ng or espeak binary, raise if missing.\"\"\"\n",
    "    exe = shutil.which(\"espeak-ng\") or shutil.which(\"espeak\")\n",
    "    if exe is None:\n",
    "        raise FileNotFoundError(\"No espeak-ng/espeak binary on PATH\")\n",
    "    return exe\n",
    "\n",
    "def phonemize(text: str, lang: str = \"en\", ipa: bool = False,\n",
    "              ipa_level: int = 1, keep_stress: bool = True) -> str:\n",
    "    \"\"\"Phonemize text using eSpeak (NG)\"\"\"\n",
    "    try: \n",
    "        exe = find_espeak()\n",
    "\n",
    "        # Build the command line\n",
    "        args = [exe, \"-q\", f\"-v{lang}\"]\n",
    "        if ipa:\n",
    "            args.append(f\"--ipa={ipa_level}\")\n",
    "        else:\n",
    "            args.append(\"-x\")\n",
    "            if not keep_stress:\n",
    "                args.append(\"--sep=-\") # do this to strip stress marks later\n",
    "        args.append(text)\n",
    "\n",
    "        # Run the command\n",
    "        proc = subprocess.run(args, text = True, capture_output = True, check = True)\n",
    "        out = proc.stdout.strip()\n",
    "\n",
    "        if not keep_stress:\n",
    "            # eSpeak stress marks are the `'` characters; remove them\n",
    "            out = out.replace(\"Ëˆ\", \"\")\n",
    "\n",
    "        # Sometimes line breaks appear in the output; remove them\n",
    "        out = out.replace(\"\\n\", \" \").replace(\"_\", \"\").replace(\"\\r\", \" \").strip()\n",
    "\n",
    "        return out\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting IPA representation, enter manually: {str(e)}\")\n",
    "        return \"???\"\n",
    "    \n",
    "def get_row(chosen_language, day, languages_df):\n",
    "    # Get language data from languages dataframe\n",
    "    languages_row = languages_df[languages_df['espeak_code'] == chosen_language].iloc[0]\n",
    "    LANGUAGE = { \n",
    "        'ESPEAK_CODE': chosen_language,\n",
    "        'ENGLISH_NAME' : languages_row['english_name'], \n",
    "        'ISO' : languages_row['iso3'],  \n",
    "        'CV' : languages_row['cv_code'], \n",
    "        'ESPEAK' : languages_row['espeak_code'], \n",
    "        'LINEAGE' : eval(languages_row['lineage']), \n",
    "        'FAMILY_0' : languages_row['family_0'], \n",
    "        'FAMILY_1' : languages_row['family_1'], \n",
    "        'FAMILY_2' : languages_row['family_2']\n",
    "    }\n",
    "\n",
    "    print(f\"Generating an example for {LANGUAGE['ENGLISH_NAME']} ({LANGUAGE['ESPEAK_CODE']})\")\n",
    "\n",
    "    # Get a sample from that language\n",
    "    LANGUAGE['SAMPLE'] = sample_common_voice(LANGUAGE['CV'])\n",
    "    LANGUAGE['SAMPLE'][0]['sentence'] = LANGUAGE['SAMPLE'][0]['sentence'].replace('\\n', ' ')\n",
    "\n",
    "    # Try to translate it\n",
    "    try:\n",
    "        LANGUAGE['SAMPLE'][0]['translation'] = translate(LANGUAGE['ENGLISH_NAME'], LANGUAGE['SAMPLE'][0]['sentence'])\n",
    "    except Exception as e:\n",
    "        print(f'Failed to add translation, enter it manually:\\n{e}')\n",
    "        LANGUAGE['SAMPLE'][0]['translation'] = '???????'\n",
    "\n",
    "    # Extract audio data of sample\n",
    "    wave = LANGUAGE['SAMPLE'][0]['audio']['array']\n",
    "    rate = LANGUAGE['SAMPLE'][0]['audio']['sampling_rate']\n",
    "\n",
    "    # Convert to phonetics\n",
    "    LANGUAGE['SAMPLE'][0]['IPA'] = phonemize(text = LANGUAGE['SAMPLE'][0]['sentence'], lang = LANGUAGE['ESPEAK'], ipa = True, ipa_level = 1, keep_stress = False)\n",
    "\n",
    "    # Generate and store corresponding audio file\n",
    "    AUDIO_DIR = Path('assets/audio')\n",
    "    AUDIO_DIR.mkdir(exist_ok = True)\n",
    "    fname_base = f\"{day:%Y-%m-%d}\"\n",
    "    file_path = AUDIO_DIR / f\"{fname_base}.mp3\"\n",
    "    # muffled_file_path = AUDIO_DIR / f\"{fname_base}_muffled.mp3\"\n",
    "    # muffled_wave = sig.sosfiltfilt(sig.butter(1, 700, \"low\", fs = rate, output = \"sos\"),\n",
    "    #                          librosa.effects.pitch_shift(wave.astype(np.float32), sr = rate, n_steps = -2))\n",
    "    sf.write(file_path, wave, rate, format='MP3')\n",
    "    # sf.write(muffled_file_path, muffled_wave, rate, format='WAV')\n",
    "\n",
    "    # build a new row based on the generated LANGUAGE dict from above\n",
    "    new_row = { 'date': day,\n",
    "                'language': LANGUAGE['ENGLISH_NAME'],\n",
    "                'iso': LANGUAGE['ISO'],\n",
    "                'cv_code': LANGUAGE['CV'],\n",
    "                'espeak_code': LANGUAGE['ESPEAK'],\n",
    "                'lineage': LANGUAGE['LINEAGE'],\n",
    "                'family_0': LANGUAGE['FAMILY_0'],\n",
    "                'family_1': LANGUAGE['FAMILY_1'],\n",
    "                'family_2': LANGUAGE['FAMILY_2'],\n",
    "                'sentence': LANGUAGE['SAMPLE'][0]['sentence'],\n",
    "                'translation': LANGUAGE['SAMPLE'][0]['translation'],\n",
    "                'wave': file_path.name,\n",
    "                # 'muffled_wave': muffled_file_path.name,\n",
    "                'sampling_rate': LANGUAGE['SAMPLE'][0]['audio']['sampling_rate'],\n",
    "                'IPA': LANGUAGE['SAMPLE'][0]['IPA']\n",
    "    }\n",
    "\n",
    "    return new_row\n",
    "    \n",
    "def fill_day(chosen_language, day, languages_df, game_df, CSV_PATH):\n",
    "    new_row = get_row(chosen_language, day, languages_df)\n",
    "    # ensure any new columns are present in the dataframe\n",
    "    missing_cols = set(new_row) - set(game_df.columns)\n",
    "    for c in missing_cols:\n",
    "        game_df[c] = pd.NA # create blank column for any new field\n",
    "\n",
    "    # append and reset the index\n",
    "    game_df = pd.concat([game_df, pd.DataFrame([new_row])], ignore_index = True)\n",
    "\n",
    "    # store into the game_df\n",
    "    game_df.to_csv(CSV_PATH, index = False)\n",
    "\n",
    "    print(f\"Filled {day:%Y-%m-%d} with {new_row['language']}\\n\")\n",
    "    \n",
    "\n",
    "def replace_day(chosen_language, day, languages_df, game_df, CSV_PATH):\n",
    "    # Find index for matching date\n",
    "    datetime_object = datetime.strptime(day, \"%Y-%m-%d\").date()\n",
    "    mask = game_df['date'] == datetime_object\n",
    "    hits = mask.sum()\n",
    "    if hits == 0:\n",
    "        raise KeyError(f\"No row found with date {day}\")\n",
    "    if hits > 1:\n",
    "        raise KeyError(f\"Expected one row with date {day}, found {hits}\")\n",
    "    \n",
    "    new_row = get_row(chosen_language, datetime_object, languages_df)\n",
    "    pd_new_row = (pd.Series(new_row).reindex(game_df.columns, fill_value=pd.NA))\n",
    "    \n",
    "    idx = game_df.index[mask][0]\n",
    "    game_df.loc[idx] = pd_new_row\n",
    "\n",
    "    # store into the game_df\n",
    "    game_df.to_csv(CSV_PATH, index = False)\n",
    "\n",
    "    print(f\"Replaced {day} with {new_row['language']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074ab8b",
   "metadata": {},
   "source": [
    "## Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e4e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating an example for Welsh (cy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 7871it [00:00, 23850.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for cy that was long enough >:)\n",
      "Translation found: This article covers malnutrition and overnutrition.\n",
      "Filled 2025-12-17 with Welsh\n",
      "\n",
      "Generating an example for Macedonian (mk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 67it [00:00, 891.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for mk that was long enough >:)\n",
      "Translation found: Relativistic corrections are also needed for quantum mechanics.\n",
      "Filled 2025-12-18 with Macedonian\n",
      "\n",
      "Generating an example for Tamil (ta)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 44044it [00:01, 24278.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ta that was long enough >:)\n",
      "Translation found: Finally, I have to write a little about the play Nandanar, which I have chosen as the seventh play.\n",
      "Filled 2025-12-19 with Tamil\n",
      "\n",
      "Generating an example for Georgian (ka)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 39326it [00:02, 16778.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ka that was long enough >:)\n",
      "Translation found: The first five books in the series review the facts of The Silmarillion and related events.\n",
      "Filled 2025-12-20 with Georgian\n",
      "\n",
      "Generating an example for Turkish (tr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 31465it [00:01, 28225.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for tr but it was too short :3\n",
      "Translation found: Come on, come out.\n",
      "Filled 2025-12-21 with Turkish\n",
      "\n",
      "Generating an example for Swedish (sv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 7584it [00:00, 29453.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sv-SE that was long enough >:)\n",
      "Translation found: I can't send a bill to the Chinese guy who peed on the carpet.\n",
      "Filled 2025-12-22 with Swedish\n",
      "\n",
      "Generating an example for German (de)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 567993it [00:17, 32243.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for de that was long enough >:)\n",
      "Translation found: The British commander also did not consider entrenchment necessary.\n",
      "Filled 2025-12-23 with German\n",
      "\n",
      "Generating an example for Swahili (sw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 44075it [00:01, 33329.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sw that was long enough >:)\n",
      "Error: 'NoneType' object has no attribute 'is_displayed'\n",
      "Filled 2025-12-24 with Swahili\n",
      "\n",
      "Generating an example for Nepali (ne)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 194it [00:00, 3140.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for ne-NP that was long enough >:)\n",
      "Translation found: Yes, the dozer should have been used in the open field, but after following the procedure.\n",
      "Filled 2025-12-25 with Nepali\n",
      "\n",
      "Generating an example for Persian (fa)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 28756it [00:00, 31804.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m next_day = (\u001b[38;5;28mmax\u001b[39m(game_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]) + timedelta(days = \u001b[32m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m game_df.empty \u001b[38;5;28;01melse\u001b[39;00m START_DAY\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Fill in the next day with an example of the chosen language\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mfill_day\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_language\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_day\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguages_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 219\u001b[39m, in \u001b[36mfill_day\u001b[39m\u001b[34m(chosen_language, day, languages_df, game_df, CSV_PATH)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfill_day\u001b[39m(chosen_language, day, languages_df, game_df, CSV_PATH):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     new_row = \u001b[43mget_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_language\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguages_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# ensure any new columns are present in the dataframe\u001b[39;00m\n\u001b[32m    221\u001b[39m     missing_cols = \u001b[38;5;28mset\u001b[39m(new_row) - \u001b[38;5;28mset\u001b[39m(game_df.columns)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 170\u001b[39m, in \u001b[36mget_row\u001b[39m\u001b[34m(chosen_language, day, languages_df)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating an example for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLANGUAGE[\u001b[33m'\u001b[39m\u001b[33mENGLISH_NAME\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLANGUAGE[\u001b[33m'\u001b[39m\u001b[33mESPEAK_CODE\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Get a sample from that language\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m LANGUAGE[\u001b[33m'\u001b[39m\u001b[33mSAMPLE\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43msample_common_voice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLANGUAGE\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCV\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m LANGUAGE[\u001b[33m'\u001b[39m\u001b[33mSAMPLE\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m] = LANGUAGE[\u001b[33m'\u001b[39m\u001b[33mSAMPLE\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m].replace(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Try to translate it\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36msample_common_voice\u001b[39m\u001b[34m(cv_code)\u001b[39m\n\u001b[32m     30\u001b[39m seed = random.randint(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m32\u001b[39m - \u001b[32m1\u001b[39m)\n\u001b[32m     31\u001b[39m ds_shuffled = ds_stream.shuffle(buffer_size=\u001b[32m2048\u001b[39m, seed=seed)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m samples = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds_shuffled\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample[\u001b[33m'\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33marray\u001b[39m\u001b[33m'\u001b[39m].shape[\u001b[32m0\u001b[39m] >= \u001b[32m200000\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:2270\u001b[39m, in \u001b[36mIterableDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2267\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m formatter.format_row(pa_table)\n\u001b[32m   2268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2270\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2271\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# no need to format thanks to FormattedExamplesIterable\u001b[39;49;00m\n\u001b[32m   2272\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:1856\u001b[39m, in \u001b[36mFormattedExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1849\u001b[39m     formatter = get_formatter(\n\u001b[32m   1850\u001b[39m         \u001b[38;5;28mself\u001b[39m.formatting.format_type,\n\u001b[32m   1851\u001b[39m         features=\u001b[38;5;28mself\u001b[39m._features \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable.is_typed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1852\u001b[39m         token_per_repo_id=\u001b[38;5;28mself\u001b[39m.token_per_repo_id,\n\u001b[32m   1853\u001b[39m     )\n\u001b[32m   1854\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable.iter_arrow:\n\u001b[32m   1855\u001b[39m     \u001b[38;5;66;03m# feature casting (inc column addition) handled within self._iter_arrow()\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_batch_to_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:1879\u001b[39m, in \u001b[36mFormattedExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1877\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features:\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable._iter_arrow()\n\u001b[32m-> \u001b[39m\u001b[32m1879\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_iter_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43marrow_schema\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:476\u001b[39m, in \u001b[36mRebatchedArrowExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    474\u001b[39m     previous_state = \u001b[38;5;28mself\u001b[39m.ex_iterable.state_dict()\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mprevious_state\u001b[39m\u001b[33m\"\u001b[39m] = previous_state\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_chunks_since_previous_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_chunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_chunks_to_skip\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:128\u001b[39m, in \u001b[36m_convert_to_arrow\u001b[39m\u001b[34m(iterable, batch_size, drop_last_batch)\u001b[39m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    127\u001b[39m iterator = \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43miterator_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_examples_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:1722\u001b[39m, in \u001b[36mTakeExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1720\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1721\u001b[39m     ex_iterable_num_taken = \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mnum_taken\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1722\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey_example\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mex_iterable_num_taken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_taken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:1535\u001b[39m, in \u001b[36mBufferShuffledExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1533\u001b[39m \u001b[38;5;66;03m# this is the shuffle buffer that we keep in memory\u001b[39;00m\n\u001b[32m   1534\u001b[39m mem_buffer = []\n\u001b[32m-> \u001b[39m\u001b[32m1535\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmem_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if the buffer is full, pick and example from it\u001b[39;49;00m\n\u001b[32m   1537\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/iterable_dataset.py:265\u001b[39m, in \u001b[36mShuffledDataSourcesExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen_kwags \u001b[38;5;129;01min\u001b[39;00m islice(\n\u001b[32m    262\u001b[39m     _split_gen_kwargs(kwargs_with_shuffled_shards, max_num_jobs=\u001b[38;5;28mself\u001b[39m.num_shards), shard_idx_start, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    263\u001b[39m ):\n\u001b[32m    264\u001b[39m     shard_example_idx_start = \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mshard_example_idx\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey_example\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_examples_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgen_kwags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_example_idx_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshard_example_idx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/datasets_modules/datasets/mozilla-foundation--common_voice_15_0/74e497a1be7b690fe79155a67473c3b207cec144dc2a92d0a7bdd19172d3a4d9/common_voice_15_0.py:196\u001b[39m, in \u001b[36mCommonVoice._generate_examples\u001b[39m\u001b[34m(self, local_extracted_archive_paths, archives, meta_path)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# set the audio feature and the path to the extracted file\u001b[39;00m\n\u001b[32m    195\u001b[39m path = os.path.join(local_extracted_archive_paths[i], path) \u001b[38;5;28;01mif\u001b[39;00m local_extracted_archive_paths \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m result[\u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: path, \u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[32m    197\u001b[39m result[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m] = path\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m path, result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tarfile.py:694\u001b[39m, in \u001b[36m_FileInFile.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m    693\u001b[39m     \u001b[38;5;28mself\u001b[39m.fileobj.seek(offset + (\u001b[38;5;28mself\u001b[39m.position - start))\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     b = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) != length:\n\u001b[32m    696\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ReadError(\u001b[33m\"\u001b[39m\u001b[33munexpected end of data\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tarfile.py:527\u001b[39m, in \u001b[36m_Stream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the next size number of bytes from the stream.\"\"\"\u001b[39;00m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28mself\u001b[39m.pos += \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m buf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tarfile.py:535\u001b[39m, in \u001b[36m_Stream._read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return size bytes from the stream.\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.comptype == \u001b[33m\"\u001b[39m\u001b[33mtar\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__read\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m c = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dbuf)\n\u001b[32m    538\u001b[39m t = [\u001b[38;5;28mself\u001b[39m.dbuf]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tarfile.py:565\u001b[39m, in \u001b[36m_Stream.__read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    563\u001b[39m t = [\u001b[38;5;28mself\u001b[39m.buf]\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m c < size:\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[32m    567\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/datasets/utils/file_utils.py:827\u001b[39m, in \u001b[36m_add_retries_to_file_obj_read_method.<locals>.read_with_retries\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m retry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, max_retries + \u001b[32m1\u001b[39m):\n\u001b[32m    826\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m         out = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    828\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    830\u001b[39m         _AiohttpClientError,\n\u001b[32m    831\u001b[39m         asyncio.TimeoutError,\n\u001b[32m    832\u001b[39m         requests.exceptions.ConnectionError,\n\u001b[32m    833\u001b[39m         requests.exceptions.Timeout,\n\u001b[32m    834\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/huggingface_hub/hf_file_system.py:757\u001b[39m, in \u001b[36mHfFileSystemFile.read\u001b[39m\u001b[34m(self, length)\u001b[39m\n\u001b[32m    755\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fs.open(\u001b[38;5;28mself\u001b[39m.path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m, block_size=\u001b[32m0\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# block_size=0 enables fast streaming\u001b[39;00m\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/fsspec/spec.py:2083\u001b[39m, in \u001b[36mAbstractBufferedFile.read\u001b[39m\u001b[34m(self, length)\u001b[39m\n\u001b[32m   2080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m length == \u001b[32m0\u001b[39m:\n\u001b[32m   2081\u001b[39m     \u001b[38;5;66;03m# don't even bother calling fetch\u001b[39;00m\n\u001b[32m   2082\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2083\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2085\u001b[39m logger.debug(\n\u001b[32m   2086\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m read: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2087\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2090\u001b[39m     \u001b[38;5;28mself\u001b[39m.cache._log_stats(),\n\u001b[32m   2091\u001b[39m )\n\u001b[32m   2092\u001b[39m \u001b[38;5;28mself\u001b[39m.loc += \u001b[38;5;28mlen\u001b[39m(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/fsspec/caching.py:249\u001b[39m, in \u001b[36mReadAheadCache._fetch\u001b[39m\u001b[34m(self, start, end)\u001b[39m\n\u001b[32m    247\u001b[39m end = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.size, end + \u001b[38;5;28mself\u001b[39m.blocksize)\n\u001b[32m    248\u001b[39m \u001b[38;5;28mself\u001b[39m.total_requested_bytes += end - start\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28mself\u001b[39m.cache = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# new block replaces old\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;28mself\u001b[39m.start = start\n\u001b[32m    251\u001b[39m \u001b[38;5;28mself\u001b[39m.end = \u001b[38;5;28mself\u001b[39m.start + \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cache)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/huggingface_hub/hf_file_system.py:713\u001b[39m, in \u001b[36mHfFileSystemFile._fetch_range\u001b[39m\u001b[34m(self, start, end)\u001b[39m\n\u001b[32m    702\u001b[39m headers = {\n\u001b[32m    703\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrange\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    704\u001b[39m     **\u001b[38;5;28mself\u001b[39m.fs._api._build_hf_headers(),\n\u001b[32m    705\u001b[39m }\n\u001b[32m    706\u001b[39m url = hf_hub_url(\n\u001b[32m    707\u001b[39m     repo_id=\u001b[38;5;28mself\u001b[39m.resolved_path.repo_id,\n\u001b[32m    708\u001b[39m     revision=\u001b[38;5;28mself\u001b[39m.resolved_path.revision,\n\u001b[32m   (...)\u001b[39m\u001b[32m    711\u001b[39m     endpoint=\u001b[38;5;28mself\u001b[39m.fs.endpoint,\n\u001b[32m    712\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m r = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m502\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m503\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m504\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m hf_raise_for_status(r)\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:307\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    306\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:93\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     95\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langr/.venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# All available languages, removing english\n",
    "languages_df = pd.read_csv(LANGUAGE_DATA_PATH)\n",
    "all_languages = languages_df['espeak_code'].unique()\n",
    "for code in ['en', 'en-gb', 'en-sc', 'en-uk-north', 'en-uk-wmids', 'en-us', 'en-wi']:\n",
    "    all_languages = np.delete(all_languages, np.where(all_languages == code))\n",
    "all_languages\n",
    "\n",
    "# Select number_to_generate many languages, with some non-repetition baked into this choice\n",
    "sample = sample_with_repeat_rounds(list(all_languages), number_to_generate)\n",
    "\n",
    "START_DAY = date(2025, 6, 13) # first day in the daily games series\n",
    "\n",
    "# Generate examples\n",
    "for chosen_language in sample:\n",
    "\n",
    "    # Load the dataframe\n",
    "    if CSV_PATH.exists():\n",
    "        game_df = pd.read_csv(CSV_PATH, parse_dates = ['date'])\n",
    "        # mutate the column to a Python date, not Timestamp\n",
    "        game_df['date'] = game_df['date'].dt.date\n",
    "    else:\n",
    "        game_df = pd.DataFrame(columns=['date'])\n",
    "\n",
    "    # Decide date to which this example corresponds\n",
    "    next_day = (max(game_df['date']) + timedelta(days = 1)) if not game_df.empty else START_DAY\n",
    "\n",
    "    # Fill in the next day with an example of the chosen language\n",
    "    fill_day(chosen_language, next_day, languages_df, game_df, CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ea99e",
   "metadata": {},
   "source": [
    "## Replacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615f81e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating an example for Swahili (sw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 44075it [00:02, 16429.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample from Common Voice dataset for sw that was long enough >:)\n",
      "Clicked target language dropdown\n",
      "Translation found: denied entry to Chinese people, the law aimed to reduce\n",
      "Replaced 2025-07-01 with Swahili)\n"
     ]
    }
   ],
   "source": [
    "# Manually replacing\n",
    "date_string = \"2025-07-01\"\n",
    "\n",
    "# Load the dataframe\n",
    "if CSV_PATH.exists():\n",
    "    game_df = pd.read_csv(CSV_PATH, parse_dates = ['date'])\n",
    "    game_df['date'] = game_df['date'].dt.date\n",
    "else:\n",
    "    game_df = pd.DataFrame(columns=['date'])\n",
    "\n",
    "# Replace the example for this date with language of choice\n",
    "replace_day('sw', date_string, pd.read_csv(LANGUAGE_DATA_PATH), game_df, Path(GAME_DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9a419",
   "metadata": {},
   "source": [
    "## View Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c78d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>iso</th>\n",
       "      <th>family_2</th>\n",
       "      <th>translation</th>\n",
       "      <th>sentence</th>\n",
       "      <th>family_0</th>\n",
       "      <th>lineage</th>\n",
       "      <th>espeak_code</th>\n",
       "      <th>family_1</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>IPA</th>\n",
       "      <th>wave</th>\n",
       "      <th>language</th>\n",
       "      <th>cv_code</th>\n",
       "      <th>muffled_wave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>hin</td>\n",
       "      <td>Shaurasenic</td>\n",
       "      <td>These apps will make your train journey easier</td>\n",
       "      <td>à¤¯à¥‡ à¤à¤ªà¥à¤¸ à¤†à¤ªà¤•à¥‡ à¤Ÿà¥à¤°à¥‡à¤¨ à¤•à¥‡ à¤¸à¤«à¤° à¤•à¥‹ à¤¬à¤¨à¤¾à¤à¤‚à¤—à¥‡ à¤”à¤° à¤†à¤¸à¤¾à¤¨</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>hi</td>\n",
       "      <td>Indo-Iranian</td>\n",
       "      <td>48000</td>\n",
       "      <td>jeË ËˆeËps ËŒaËpkËŒeË ÊˆÉ¾ËˆeËn keË sËˆÊŒpÊ°É™É¾ koË bËŒÉ™n...</td>\n",
       "      <td>2025-07-06.mp3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>hi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>vie</td>\n",
       "      <td>Viet-Muong</td>\n",
       "      <td>I took the pack of cigarettes out to the porch...</td>\n",
       "      <td>TÃ´i cáº§m bao thuá»‘c ra bÃªn ngoÃ i hiÃªn hÃ³ng giÃ³</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...</td>\n",
       "      <td>vi</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>48000</td>\n",
       "      <td>tÌªËˆoÍ¡Éª1 É¡ËˆÉ™2m bËˆaËÍ¡ÊŠ1 tËˆuÍ¡É™ÉœkÍ¡h zËˆaË1 bËˆe1n Å‹Ëˆ...</td>\n",
       "      <td>2025-07-07.mp3</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>vi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>nep</td>\n",
       "      <td>Eastern Pahari</td>\n",
       "      <td>If anyone has a program that can be held on th...</td>\n",
       "      <td>à¤¯à¤¦à¤¿ à¤•à¤¸à¥ˆà¤•à¥‹ à¤•à¥à¤¯à¤¾à¤®à¥à¤ªà¤¸à¤®à¤¾ à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤® à¤—à¤°à¥à¤¨ à¤®à¤¿à¤²à¥à¤¨à¥‡ à¤› à¤­...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>ne</td>\n",
       "      <td>Indo-Iranian</td>\n",
       "      <td>48000</td>\n",
       "      <td>jËˆÊŒdÉª kÉ™sËˆÉ›ËkoË kËjËˆaËmpÉ™sËŒÉ™maË kËˆaËÉ¾rjÉ™kÉ¾ËŒÉ™mÉ™...</td>\n",
       "      <td>2025-07-08.mp3</td>\n",
       "      <td>Nepali</td>\n",
       "      <td>ne-NP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>vie</td>\n",
       "      <td>Vietâ€“MÆ°á»ng</td>\n",
       "      <td>Looking at the clock, it was already ten o'clo...</td>\n",
       "      <td>NhÃ¬n Ä‘á»“ng há»“ lÃºc nÃ y cÅ©ng Ä‘Ã£ lÃ  mÆ°á»i giá» tá»‘i</td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td>['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...</td>\n",
       "      <td>vi-hue</td>\n",
       "      <td>Vietic</td>\n",
       "      <td>48000</td>\n",
       "      <td>É²Ëˆi2Å‹ É—Ëˆo2 hËˆo2 lËŒuÉœkÍ¡h nËˆaÍ¡Éª2 É¡Ëˆu5Å‹ É—ËŒaË5 lËŒa...</td>\n",
       "      <td>2025-07-09.mp3</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>vi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>ell</td>\n",
       "      <td>Modern Koineic</td>\n",
       "      <td>His knees buckled for a moment and he leaned a...</td>\n",
       "      <td>Î¤Î± Î³ÏŒÎ½Î±Ï„Î¬ Ï„Î¿Ï… ÎºÏŒÏ€Î·ÎºÎ±Î½ Ï€ÏÎ¿Ï‚ ÏƒÏ„Î¹Î³Î¼Î® ÎºÎ±Î¹ Î±ÎºÎ¿ÏÎ¼Ï€Î·Ïƒ...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>el</td>\n",
       "      <td>Graeco-Phrygian</td>\n",
       "      <td>48000</td>\n",
       "      <td>ta É£ËˆonatËˆa tu kËˆopikËŒam brËˆos stiÉ£mËˆi ke akËˆu...</td>\n",
       "      <td>2025-07-10.mp3</td>\n",
       "      <td>Greek</td>\n",
       "      <td>el</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>cym</td>\n",
       "      <td>Brythonic</td>\n",
       "      <td>Porridge is oatmeal boiled in water or milk.</td>\n",
       "      <td>Blawd ceirch wedi'i ferwi mewn dÅµr neu laeth y...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>cy</td>\n",
       "      <td>Celtic</td>\n",
       "      <td>48000</td>\n",
       "      <td>blËˆaÍ¡ÊŠd kËˆÉ™Í¡Éªrx wÉ›dËˆiËÉ¨ vËˆÉ›rwÉ¨ meÍ¡ÊŠn dËˆuËr nËˆÉ™...</td>\n",
       "      <td>2025-07-11.mp3</td>\n",
       "      <td>Welsh</td>\n",
       "      <td>cy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-07-12</td>\n",
       "      <td>mkd</td>\n",
       "      <td>South Slavic</td>\n",
       "      <td>The houses are incredibly realistic, with mode...</td>\n",
       "      <td>ÐšÑƒÑœÐ¸Ñ‡ÐºÐ¸Ñ‚Ðµ ÑÐµ Ð½ÐµÐ²ÐµÑ€Ð¾Ñ˜Ð°Ñ‚Ð½Ð¾ Ñ€ÐµÐ°Ð»Ð½Ð¸, ÑÐ¾ Ð¼Ð¾Ð´ÐµÑ€Ð½Ð¸ Ð´Ðµ...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>mk</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>48000</td>\n",
       "      <td>kÊŠk^ËˆitÍ¡É•kÉªtËŒe se nËŒeverËˆojÃ¦tnËŒo rËˆeÃ¦lnËŒÉª\\n s ...</td>\n",
       "      <td>2025-07-12.mp3</td>\n",
       "      <td>Macedonian</td>\n",
       "      <td>mk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-07-13</td>\n",
       "      <td>lit</td>\n",
       "      <td>Eastern Baltic</td>\n",
       "      <td>Its area is about half the area of Abruzzo.</td>\n",
       "      <td>Jos plotas sudaro apie pusÄ™ AbrucÅ³ ploto.</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>lt</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "      <td>48000</td>\n",
       "      <td>jËˆoËs plÌ©ËˆoËtas sudËˆaroË ËˆapÊ²iÍ¡e pËˆuÊ‚eÍ¡É‘ abrËˆu...</td>\n",
       "      <td>2025-07-13.mp3</td>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>lt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>fin</td>\n",
       "      <td>Coastal Finnic</td>\n",
       "      <td>Or has some other species, perhaps a bacterium...</td>\n",
       "      <td>Vai onko jokin muu laji, bakteeri kenties, tuh...</td>\n",
       "      <td>Uralic</td>\n",
       "      <td>['Uralic', 'Finnic', 'Coastal Finnic', 'Neva',...</td>\n",
       "      <td>fi</td>\n",
       "      <td>Finnic</td>\n",
       "      <td>48000</td>\n",
       "      <td>vaÍ¡i ËˆoÅ‹ko jËˆokÉªn mËˆuË lËˆajÉª\\n bËˆakteËrÉª kËˆent...</td>\n",
       "      <td>2025-07-14.mp3</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>fi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-07-15</td>\n",
       "      <td>afr</td>\n",
       "      <td>Macro-Dutch</td>\n",
       "      <td>Your school choir performed the choral works b...</td>\n",
       "      <td>Jou skoolkoor het die koorwerke hieronder gedu...</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>['Indo-European', 'Classical Indo-European', '...</td>\n",
       "      <td>af</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>48000</td>\n",
       "      <td>jÉ™Í¡ÊŠ skËˆÊŠÍ¡É™lkÊŠÍ¡É™r hÉ› di kËˆÊŠÍ¡É™rvÃ¦rkÉ™ hËˆiËrÉ”nÉ™r ...</td>\n",
       "      <td>2025-07-15.mp3</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>af</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  iso        family_2  \\\n",
       "23  2025-07-06  hin     Shaurasenic   \n",
       "24  2025-07-07  vie      Viet-Muong   \n",
       "25  2025-07-08  nep  Eastern Pahari   \n",
       "26  2025-07-09  vie      Vietâ€“MÆ°á»ng   \n",
       "27  2025-07-10  ell  Modern Koineic   \n",
       "28  2025-07-11  cym       Brythonic   \n",
       "29  2025-07-12  mkd    South Slavic   \n",
       "30  2025-07-13  lit  Eastern Baltic   \n",
       "31  2025-07-14  fin  Coastal Finnic   \n",
       "32  2025-07-15  afr     Macro-Dutch   \n",
       "\n",
       "                                          translation  \\\n",
       "23     These apps will make your train journey easier   \n",
       "24  I took the pack of cigarettes out to the porch...   \n",
       "25  If anyone has a program that can be held on th...   \n",
       "26  Looking at the clock, it was already ten o'clo...   \n",
       "27  His knees buckled for a moment and he leaned a...   \n",
       "28       Porridge is oatmeal boiled in water or milk.   \n",
       "29  The houses are incredibly realistic, with mode...   \n",
       "30        Its area is about half the area of Abruzzo.   \n",
       "31  Or has some other species, perhaps a bacterium...   \n",
       "32  Your school choir performed the choral works b...   \n",
       "\n",
       "                                             sentence       family_0  \\\n",
       "23       à¤¯à¥‡ à¤à¤ªà¥à¤¸ à¤†à¤ªà¤•à¥‡ à¤Ÿà¥à¤°à¥‡à¤¨ à¤•à¥‡ à¤¸à¤«à¤° à¤•à¥‹ à¤¬à¤¨à¤¾à¤à¤‚à¤—à¥‡ à¤”à¤° à¤†à¤¸à¤¾à¤¨  Indo-European   \n",
       "24       TÃ´i cáº§m bao thuá»‘c ra bÃªn ngoÃ i hiÃªn hÃ³ng giÃ³  Austroasiatic   \n",
       "25  à¤¯à¤¦à¤¿ à¤•à¤¸à¥ˆà¤•à¥‹ à¤•à¥à¤¯à¤¾à¤®à¥à¤ªà¤¸à¤®à¤¾ à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤® à¤—à¤°à¥à¤¨ à¤®à¤¿à¤²à¥à¤¨à¥‡ à¤› à¤­...  Indo-European   \n",
       "26       NhÃ¬n Ä‘á»“ng há»“ lÃºc nÃ y cÅ©ng Ä‘Ã£ lÃ  mÆ°á»i giá» tá»‘i  Austroasiatic   \n",
       "27  Î¤Î± Î³ÏŒÎ½Î±Ï„Î¬ Ï„Î¿Ï… ÎºÏŒÏ€Î·ÎºÎ±Î½ Ï€ÏÎ¿Ï‚ ÏƒÏ„Î¹Î³Î¼Î® ÎºÎ±Î¹ Î±ÎºÎ¿ÏÎ¼Ï€Î·Ïƒ...  Indo-European   \n",
       "28  Blawd ceirch wedi'i ferwi mewn dÅµr neu laeth y...  Indo-European   \n",
       "29  ÐšÑƒÑœÐ¸Ñ‡ÐºÐ¸Ñ‚Ðµ ÑÐµ Ð½ÐµÐ²ÐµÑ€Ð¾Ñ˜Ð°Ñ‚Ð½Ð¾ Ñ€ÐµÐ°Ð»Ð½Ð¸, ÑÐ¾ Ð¼Ð¾Ð´ÐµÑ€Ð½Ð¸ Ð´Ðµ...  Indo-European   \n",
       "30          Jos plotas sudaro apie pusÄ™ AbrucÅ³ ploto.  Indo-European   \n",
       "31  Vai onko jokin muu laji, bakteeri kenties, tuh...         Uralic   \n",
       "32  Jou skoolkoor het die koorwerke hieronder gedu...  Indo-European   \n",
       "\n",
       "                                              lineage espeak_code  \\\n",
       "23  ['Indo-European', 'Classical Indo-European', '...          hi   \n",
       "24  ['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...          vi   \n",
       "25  ['Indo-European', 'Classical Indo-European', '...          ne   \n",
       "26  ['Austroasiatic', 'Vietic', 'Viet-Muong', 'Vie...      vi-hue   \n",
       "27  ['Indo-European', 'Classical Indo-European', '...          el   \n",
       "28  ['Indo-European', 'Classical Indo-European', '...          cy   \n",
       "29  ['Indo-European', 'Classical Indo-European', '...          mk   \n",
       "30  ['Indo-European', 'Classical Indo-European', '...          lt   \n",
       "31  ['Uralic', 'Finnic', 'Coastal Finnic', 'Neva',...          fi   \n",
       "32  ['Indo-European', 'Classical Indo-European', '...          af   \n",
       "\n",
       "           family_1  sampling_rate  \\\n",
       "23     Indo-Iranian          48000   \n",
       "24           Vietic          48000   \n",
       "25     Indo-Iranian          48000   \n",
       "26           Vietic          48000   \n",
       "27  Graeco-Phrygian          48000   \n",
       "28           Celtic          48000   \n",
       "29     Balto-Slavic          48000   \n",
       "30     Balto-Slavic          48000   \n",
       "31           Finnic          48000   \n",
       "32         Germanic          48000   \n",
       "\n",
       "                                                  IPA            wave  \\\n",
       "23  jeË ËˆeËps ËŒaËpkËŒeË ÊˆÉ¾ËˆeËn keË sËˆÊŒpÊ°É™É¾ koË bËŒÉ™n...  2025-07-06.mp3   \n",
       "24  tÌªËˆoÍ¡Éª1 É¡ËˆÉ™2m bËˆaËÍ¡ÊŠ1 tËˆuÍ¡É™ÉœkÍ¡h zËˆaË1 bËˆe1n Å‹Ëˆ...  2025-07-07.mp3   \n",
       "25  jËˆÊŒdÉª kÉ™sËˆÉ›ËkoË kËjËˆaËmpÉ™sËŒÉ™maË kËˆaËÉ¾rjÉ™kÉ¾ËŒÉ™mÉ™...  2025-07-08.mp3   \n",
       "26  É²Ëˆi2Å‹ É—Ëˆo2 hËˆo2 lËŒuÉœkÍ¡h nËˆaÍ¡Éª2 É¡Ëˆu5Å‹ É—ËŒaË5 lËŒa...  2025-07-09.mp3   \n",
       "27  ta É£ËˆonatËˆa tu kËˆopikËŒam brËˆos stiÉ£mËˆi ke akËˆu...  2025-07-10.mp3   \n",
       "28  blËˆaÍ¡ÊŠd kËˆÉ™Í¡Éªrx wÉ›dËˆiËÉ¨ vËˆÉ›rwÉ¨ meÍ¡ÊŠn dËˆuËr nËˆÉ™...  2025-07-11.mp3   \n",
       "29  kÊŠk^ËˆitÍ¡É•kÉªtËŒe se nËŒeverËˆojÃ¦tnËŒo rËˆeÃ¦lnËŒÉª\\n s ...  2025-07-12.mp3   \n",
       "30  jËˆoËs plÌ©ËˆoËtas sudËˆaroË ËˆapÊ²iÍ¡e pËˆuÊ‚eÍ¡É‘ abrËˆu...  2025-07-13.mp3   \n",
       "31  vaÍ¡i ËˆoÅ‹ko jËˆokÉªn mËˆuË lËˆajÉª\\n bËˆakteËrÉª kËˆent...  2025-07-14.mp3   \n",
       "32  jÉ™Í¡ÊŠ skËˆÊŠÍ¡É™lkÊŠÍ¡É™r hÉ› di kËˆÊŠÍ¡É™rvÃ¦rkÉ™ hËˆiËrÉ”nÉ™r ...  2025-07-15.mp3   \n",
       "\n",
       "      language cv_code  muffled_wave  \n",
       "23       Hindi      hi           NaN  \n",
       "24  Vietnamese      vi           NaN  \n",
       "25      Nepali   ne-NP           NaN  \n",
       "26  Vietnamese      vi           NaN  \n",
       "27       Greek      el           NaN  \n",
       "28       Welsh      cy           NaN  \n",
       "29  Macedonian      mk           NaN  \n",
       "30  Lithuanian      lt           NaN  \n",
       "31     Finnish      fi           NaN  \n",
       "32   Afrikaans      af           NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_df.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
